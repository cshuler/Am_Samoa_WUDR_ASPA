{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1eecd176",
   "metadata": {},
   "source": [
    "# Python Script for ASPA WUDR Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8135b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import relevant packages\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import requests\n",
    "import boto3\n",
    "from io import BytesIO, StringIO\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b9f1659",
   "metadata": {},
   "outputs": [],
   "source": [
    "##DELETE IMMIDIATELY ONCE SET ##\n",
    "os.environ['GITHUB_TOKEN'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e134a262",
   "metadata": {},
   "source": [
    "## Access Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aad146a",
   "metadata": {},
   "source": [
    "The water usage data files are stored in a private github repo. They are all formated as excel files and can be accessed from the repo with a GitHub_token from anyone granted access. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8993b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://raw.githubusercontent.com/cshuler/ASPA_WUDR_Input_Files/main/Data/2022/2022/Water%20Usage%20Sales%20prompt%20by%20billing_202201a.xlsx?token=AHFNTV6O2Z6KTX4KOQH7O2DGZ6NHW', 'https://raw.githubusercontent.com/cshuler/ASPA_WUDR_Input_Files/main/Data/2022/2022/Water%20Usage%20Sales%20prompt%20by%20billing_202202a.xlsx?token=AHFNTV2ZVTPH2NMGV6CDYNDGZ6NHW', 'https://raw.githubusercontent.com/cshuler/ASPA_WUDR_Input_Files/main/Data/2022/2022/Water%20Usage%20Sales%20prompt%20by%20billing_202203a.xlsx?token=AHFNTV4DVXNY3UF4XMXQ7B3GZ6NHW', 'https://raw.githubusercontent.com/cshuler/ASPA_WUDR_Input_Files/main/Data/2022/2022/Water%20Usage%20Sales%20prompt%20by%20billing_202204a.xlsx?token=AHFNTV55QTYUXQEMKHZNC43GZ6NHW', 'https://raw.githubusercontent.com/cshuler/ASPA_WUDR_Input_Files/main/Data/2022/2022/Water%20Usage%20Sales%20prompt%20by%20billing_202205a.xlsx?token=AHFNTVZYRVJK33AWX6E3WYTGZ6NHW']\n"
     ]
    }
   ],
   "source": [
    "def get_xlsx_files_from_repo(repo_url, token):\n",
    "    headers = {\n",
    "        'Authorization': f'token {token}'\n",
    "    }\n",
    "    response = requests.get(repo_url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        items = response.json()\n",
    "        xlsx_files = []\n",
    "        for item in items:\n",
    "            if item['type'] == 'file' and item['name'].endswith('.xlsx'):\n",
    "                xlsx_files.append(item['download_url'])\n",
    "            elif item['type'] == 'dir':\n",
    "                xlsx_files += get_xlsx_files_from_repo(item['url'], token)\n",
    "        return xlsx_files\n",
    "    else:\n",
    "        raise ValueError(f\"Failed to fetch repository contents: {response.status_code}\")\n",
    "        \n",
    "repo_url = \"https://api.github.com/repos/cshuler/ASPA_WUDR_Input_Files/contents/Data/2022\"\n",
    "token = os.environ.get('GITHUB_TOKEN')\n",
    "if not token:\n",
    "    raise ValueError(\"GitHub token not found in environment variables\")\n",
    "\n",
    "xlsx_files = get_xlsx_files_from_repo(repo_url, token)\n",
    "print(xlsx_files[:5])  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859634bf",
   "metadata": {},
   "source": [
    "This confirms we have sucessfully accesed all excel files present in the repo. Now, we need convert them into dataframes, then combine all the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75778402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    HIACCT  HISUB                           NAME  Svc   Rdg Date      Rdg   \\\n",
      "0   6472.0    1.0   ASPA:WATER 911 - 341(ATUU#2)  3.0 2022-01-13  623699.0   \n",
      "1   6465.0    1.0  ASPA:WATER 900 - 341(FAGAALU)  3.0 2022-01-05   79200.0   \n",
      "2   4276.0    1.0           AFIOMAI APARTMENT #3  3.0 2022-01-19      11.0   \n",
      "3  34308.0    1.0                 SALA, FUAROSA.  3.0 2022-01-21     480.0   \n",
      "4  22280.0    1.0      AFIOMAI APARTMENT (APT#5)  3.0 2022-01-19  173563.0   \n",
      "\n",
      "        Usage  Days of Usage  Billed Amount for Water  MTH/YR OF BILLING  ...  \\\n",
      "0   4821760.0           15.0                     0.00           202201.0  ...   \n",
      "1  33283000.0           29.0                     0.00           202201.0  ...   \n",
      "2         0.0           34.0                    15.21           202201.0  ...   \n",
      "3       315.0           32.0                    16.48           202201.0  ...   \n",
      "4      7074.0           34.0                    43.66           202201.0  ...   \n",
      "\n",
      "   Rate       LOMETW Meter Size LOMPW  Unnamed: 17 30.371223603112053  \\\n",
      "0   NC3  141630302.0         2\"  19.0          NaN                NaN   \n",
      "1   NC3   96323412.0         4\"  21.0          NaN                NaN   \n",
      "2     R   90277756.0       5/8\"  23.0          NaN                NaN   \n",
      "3     R   90277755.0       5/8\"   0.0          NaN                NaN   \n",
      "4     R   90277754.0       5/8\"  23.0          NaN                NaN   \n",
      "\n",
      "   Unnamed: 18  1830  Production Rdg  \n",
      "0          NaN   NaN         NaN NaN  \n",
      "1          NaN   NaN         NaN NaN  \n",
      "2          NaN   NaN         NaN NaN  \n",
      "3          NaN   NaN         NaN NaN  \n",
      "4          NaN   NaN         NaN NaN  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "def read_xlsx_files(xlsx_files, token):\n",
    "    headers = {\n",
    "        'Authorization': f'token {token}'\n",
    "    }\n",
    "    dataframes = []\n",
    "    for file_url in xlsx_files:\n",
    "        response = requests.get(file_url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            df = pd.read_excel(BytesIO(response.content))\n",
    "            dataframes.append(df)\n",
    "        else:\n",
    "            raise ValueError(f\"Failed to download file: {response.status_code}\")\n",
    "    return dataframes\n",
    "\n",
    "#Combine all dataframes into one big dataframe\n",
    "def combine_dataframes(dataframes):\n",
    "    cs_data = pd.concat(dataframes, ignore_index=True)\n",
    "    return cs_data\n",
    "\n",
    "dataframes = read_xlsx_files(xlsx_files, token)\n",
    "cs_data = combine_dataframes(dataframes)\n",
    "print(cs_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdec051",
   "metadata": {},
   "source": [
    "## Data cleaning begins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6707b2",
   "metadata": {},
   "source": [
    "We now have our dataframe \"cs_data\" that contains all the excel files combined. This will be our main dataframe that we will work to clean before we transform/aggregate it for the final structure. We need to extract relevant information from this large dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d625e242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HIACCT</th>\n",
       "      <th>HISUB</th>\n",
       "      <th>NAME</th>\n",
       "      <th>Svc</th>\n",
       "      <th>Rdg Date</th>\n",
       "      <th>Rdg</th>\n",
       "      <th>Usage</th>\n",
       "      <th>Days of Usage</th>\n",
       "      <th>Billed Amount for Water</th>\n",
       "      <th>MTH/YR OF BILLING</th>\n",
       "      <th>...</th>\n",
       "      <th>Meter Size</th>\n",
       "      <th>LOMPW</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "      <th>30.371223603112053</th>\n",
       "      <th>Unnamed: 18</th>\n",
       "      <th>1830</th>\n",
       "      <th>Production</th>\n",
       "      <th>Rdg</th>\n",
       "      <th>SiteTypeCV</th>\n",
       "      <th>BeneficialUseCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6472.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ASPA:WATER 911 - 341(ATUU#2)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2022-01-13</td>\n",
       "      <td>623699.0</td>\n",
       "      <td>4821760.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>202201.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2\"</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Production Well</td>\n",
       "      <td>Production Well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6465.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ASPA:WATER 900 - 341(FAGAALU)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>79200.0</td>\n",
       "      <td>33283000.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>202201.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4\"</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Production Well</td>\n",
       "      <td>Production Well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4276.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AFIOMAI APARTMENT #3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2022-01-19</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>15.21</td>\n",
       "      <td>202201.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5/8\"</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Domestic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34308.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SALA, FUAROSA.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2022-01-21</td>\n",
       "      <td>480.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>16.48</td>\n",
       "      <td>202201.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5/8\"</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Domestic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22280.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AFIOMAI APARTMENT (APT#5)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2022-01-19</td>\n",
       "      <td>173563.0</td>\n",
       "      <td>7074.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>43.66</td>\n",
       "      <td>202201.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5/8\"</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Domestic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    HIACCT  HISUB                           NAME  Svc   Rdg Date       Rdg  \\\n",
       "0   6472.0    1.0   ASPA:WATER 911 - 341(ATUU#2)  3.0 2022-01-13  623699.0   \n",
       "1   6465.0    1.0  ASPA:WATER 900 - 341(FAGAALU)  3.0 2022-01-05   79200.0   \n",
       "2   4276.0    1.0           AFIOMAI APARTMENT #3  3.0 2022-01-19      11.0   \n",
       "3  34308.0    1.0                 SALA, FUAROSA.  3.0 2022-01-21     480.0   \n",
       "4  22280.0    1.0      AFIOMAI APARTMENT (APT#5)  3.0 2022-01-19  173563.0   \n",
       "\n",
       "        Usage  Days of Usage  Billed Amount for Water  MTH/YR OF BILLING  ...  \\\n",
       "0   4821760.0           15.0                     0.00           202201.0  ...   \n",
       "1  33283000.0           29.0                     0.00           202201.0  ...   \n",
       "2         0.0           34.0                    15.21           202201.0  ...   \n",
       "3       315.0           32.0                    16.48           202201.0  ...   \n",
       "4      7074.0           34.0                    43.66           202201.0  ...   \n",
       "\n",
       "   Meter Size LOMPW Unnamed: 17 30.371223603112053  Unnamed: 18 1830  \\\n",
       "0          2\"  19.0         NaN                NaN          NaN  NaN   \n",
       "1          4\"  21.0         NaN                NaN          NaN  NaN   \n",
       "2        5/8\"  23.0         NaN                NaN          NaN  NaN   \n",
       "3        5/8\"   0.0         NaN                NaN          NaN  NaN   \n",
       "4        5/8\"  23.0         NaN                NaN          NaN  NaN   \n",
       "\n",
       "   Production  Rdg       SiteTypeCV BeneficialUseCategory  \n",
       "0         NaN  NaN  Production Well       Production Well  \n",
       "1         NaN  NaN  Production Well       Production Well  \n",
       "2         NaN  NaN      Unspecified              Domestic  \n",
       "3         NaN  NaN      Unspecified              Domestic  \n",
       "4         NaN  NaN      Unspecified              Domestic  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_data(cs_data):\n",
    "    #stripping column names\n",
    "    cs_data.columns = [str(col).strip() for col in cs_data.columns]\n",
    "    cs_data = cs_data[cs_data['LOSADD'].notnull()]\n",
    "    cs_data['Usage'] = cs_data['Usage'].astype(str).str.replace(\" \", \"\")\n",
    "    cs_data['Usage'] = cs_data['Usage'].str.replace(\"-\", \"0\")\n",
    "    cs_data['Usage'] = cs_data['Usage'].str.replace(\",\", \"\")\n",
    "    cs_data['Usage'] = pd.to_numeric(cs_data['Usage'], errors='coerce')\n",
    "    pattern = re.compile(r'ASPA:WATER\\s*\\d+')\n",
    "    cs_data['SiteTypeCV'] = cs_data['NAME'].apply(lambda x: 'Production Well' if pattern.match(x) else 'Unspecified')\n",
    "    return cs_data #Creating sitetypceCV\n",
    "cs_data = clean_data(cs_data)\n",
    "\n",
    "def map_rsp_to_beneficial_use_category(cs_data): #Benenficial Use Category Definition\n",
    "    rsp_mapping = {\n",
    "        'RES': 'Domestic',\n",
    "        'IND': 'Industrial',\n",
    "        'LGS': 'Industrial',\n",
    "        'SGS': 'Commercial',\n",
    "        'ASG': 'Commercial'\n",
    "    }\n",
    "    \n",
    "    #Compile the pattern that indicates a well\n",
    "    pattern = re.compile(r'ASPA:WATER\\s*\\d+') #ASPA followed by a number. This method is further refined later when creating our well dataframe\n",
    "    \n",
    "    #Apply the mapping\n",
    "    cs_data['BeneficialUseCategory'] = cs_data['RSP'].map(rsp_mapping)\n",
    "    \n",
    "    #Update the BeneficialUseCategory to 'Well' where the pattern matches\n",
    "    cs_data['BeneficialUseCategory'] = cs_data.apply(\n",
    "        lambda row: 'Production Well' if pattern.match(row['NAME']) else row['BeneficialUseCategory'],\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    return cs_data\n",
    "cs_data = map_rsp_to_beneficial_use_category(cs_data)\n",
    "cs_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9604756e",
   "metadata": {},
   "source": [
    "### Data Cleaning: QA/QC Checks "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73049715",
   "metadata": {},
   "source": [
    "QA/QC checks for usage data. Anything greater than 3 standard deviations from the mean of a beneficial use category per month is filtered out. The well data is filtered later in the well cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3664d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa_qc_checks(cs_data):\n",
    "    cs_data['TimeframeStart'] = pd.to_datetime(cs_data['Rdg Date']) - pd.to_timedelta(cs_data['Days of Usage'], unit='D')\n",
    "    cs_data['Month'] = cs_data['TimeframeStart'].dt.to_period('M').astype(str)\n",
    "    \n",
    "    #Calculate the mean and standard deviation for each LOSADD and BeneficialUseCategory\n",
    "    cs_data['Mean'] = cs_data.groupby(['LOSADD', 'BeneficialUseCategory'])['Usage'].transform('mean')\n",
    "    cs_data['StdDev'] = cs_data.groupby(['LOSADD', 'BeneficialUseCategory'])['Usage'].transform('std')\n",
    "    cs_data['UpperLimit'] = cs_data['Mean'] + 3 * cs_data['StdDev']\n",
    "    cs_data['LowerLimit'] = cs_data['Mean'] - 3 * cs_data['StdDev']\n",
    "    \n",
    "    #Debugging\n",
    "    print(\"QA Data with Limits Preview:\")\n",
    "    print(cs_data.head())\n",
    "    cs_data.to_csv('cs_data_with_limits.csv', index=False)\n",
    "    \n",
    "    #Filtering data based on the limits\n",
    "    initial_count = len(cs_data)\n",
    "    filtered_data = cs_data[(cs_data['Usage'] >= cs_data['LowerLimit']) & (cs_data['Usage'] <= cs_data['UpperLimit'])]\n",
    "    filtered_count = len(filtered_data)\n",
    "    \n",
    "    #Print the number of data points filtered out\n",
    "    print(f\"Filtered out {initial_count - filtered_count} data points out of {initial_count}\")\n",
    "    \n",
    "    #Dropping columns used for QA/QC only if they exist\n",
    "    columns_to_drop = ['Mean', 'StdDev', 'UpperLimit', 'LowerLimit']\n",
    "    existing_columns = [col for col in columns_to_drop if col in filtered_data.columns]\n",
    "    filtered_data = filtered_data.drop(columns=existing_columns)\n",
    "    \n",
    "    #Debugging\n",
    "    print(\"Filtered Data Preview:\")\n",
    "    print(filtered_data.head())\n",
    "    filtered_data.to_csv('filtered_data.csv', index=False)\n",
    "    \n",
    "    return filtered_data\n",
    "cs_data = qa_qc_checks(cs_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13a2412",
   "metadata": {},
   "source": [
    "Defining the village key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32614f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "village_key = {\n",
    "    'AASU': \"Aasu\",\n",
    "    'AASU FOU': 'Aasu',\n",
    "    'AFAO': 'Afao',\n",
    "    'AFONO': 'Afono',\n",
    "    'AGUGULU': 'Agugulu',\n",
    "    'ALAO': 'Alao',\n",
    "    'ALEGA': 'Alega',\n",
    "    'ALOFAU': 'Alofau',\n",
    "    'AMALUIA': 'Amaluia',\n",
    "    'AMANAVE': 'Amanave',\n",
    "    'AMAUA': 'Amaua',\n",
    "    'AMOULI': 'Amouli',\n",
    "    'AOA': 'Aoa',\n",
    "    'AOLOAU': 'Aoloau',\n",
    "    'ASILI': 'Asili',\n",
    "    'ATAULOMA': 'Afao',\n",
    "    'ATUU': 'Atuu',\n",
    "    'AUA': 'Aua',\n",
    "    'AUASI': 'Auasi',\n",
    "    'AUNUU': 'Aunuu',\n",
    "    'AUTO': 'Auto',\n",
    "    'AVAIO': 'Avaio',\n",
    "    'FAGAALU': 'Fagaalu',\n",
    "    'FAGAITUA': 'Fagaitua',\n",
    "    'FAGALII': 'Fagalii',\n",
    "    'FAGAMALO': 'Fagamalo',\n",
    "    'FAGANEANEA': 'Faganeanea',\n",
    "    'FAGASA': 'Fagasa',\n",
    "    'FAGATOGO': 'Fagatogo',\n",
    "    'FAILOLO': 'Failolo',\n",
    "    'FALEASAO': 'Tau',\n",
    "    'FALENIU': 'Faleniu',\n",
    "    'FATUMAFUTI': 'Fatumafuti',\n",
    "    'FITIUTA': 'Tau',\n",
    "    'FOGAGOGO': 'Iliili', \n",
    "    'FUTIGA': 'Futiga',\n",
    "    'Fagaalu': 'Fagaalu',\n",
    "    'GATAIVAI': 'Utulei',\n",
    "    'ILIILI': 'Iliili',\n",
    "    'LAULII': 'Laulii',\n",
    "    'LELOALOA': 'Leloaloa',\n",
    "    'LEONE': 'Leone',\n",
    "    'MALAEIMI': 'Malaeimi',\n",
    "    'MALAELOA': 'Malaeloa',\n",
    "    'MALALOA': 'Fagatogo',\n",
    "    'MALOATA': 'Maloata',\n",
    "    'MAPUSAGA': 'Mapusagafou',\n",
    "    'MAPUSAGA FOU': 'Mapusagafou',\n",
    "    'MASAUSI': 'Masausi',\n",
    "    'MASEFAU': 'Masefau',\n",
    "    'MATUU': 'Matuu',\n",
    "    'MESEPA': 'Mesepa',\n",
    "    'NUA': 'Nua',\n",
    "    'NUUULI': 'Nuuuli',\n",
    "    'OFU': 'Ofu',\n",
    "    'OLOSEGA': 'Olosega',\n",
    "    'ONENOA': 'Onenoa',\n",
    "    'PAGAI': 'Pagai',\n",
    "    'PAGO PAGO': 'Pago Pago',\n",
    "    'PAVAIAI': 'Pavaiai',\n",
    "    'POLOA': 'Poloa',\n",
    "    'SAILELE': 'Sailele',\n",
    "    'SATALA': 'Pago Pago',\n",
    "    'SEETAGA': 'Seetaga',\n",
    "    'TAFETA': 'Mapusagafou',\n",
    "    'TAFUNA': 'Tafuna',\n",
    "    'TAPUTIMU': 'Taputimu',\n",
    "    'TAU': 'Tau',\n",
    "    'TULA': 'Tula',\n",
    "    'UTULEI': 'Utulei',\n",
    "    'UTUMEA': 'Utumea West',\n",
    "    'UTUMEA-SASAE': 'Utumea East',\n",
    "    'UTUSIA': 'Fagaitua',\n",
    "    'VAILOA': 'Vailoatai',\n",
    "    'VAITOGI': 'Vaitogi',\n",
    "    'VATIA': 'Vatia',\n",
    "    'Vaitogi': 'Vaitogi'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a25c90",
   "metadata": {},
   "source": [
    "### Data Cleaning: Transforming and Aggreating Main Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7502d08c",
   "metadata": {},
   "source": [
    "This is where the data from cs_data is transfered into another dataframe where the columns specified by Wade Schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2781cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_site_specific_format(cs_data):\n",
    "   \n",
    "    \n",
    "   transformed_data = pd.DataFrame(columns=['SiteNativeID','VariableSpecificUUID', 'Amount', 'BeneficialUseCategory', 'TimeframeStart', 'TimeframeEnd'])\n",
    "    \n",
    "   # Map the villages using SiteNativeID\n",
    "   transformed_data['SiteNativeID'] = cs_data['LOSADD'].map(village_key) #use of village key\n",
    "   transformed_data['VariableSpecificUUID'] = 'UTssps_V3'\n",
    "   transformed_data['Amount'] = cs_data['Usage']\n",
    "   transformed_data['BeneficialUseCategory'] = cs_data['BeneficialUseCategory']\n",
    "\n",
    "   cs_data['MTH/YR OF BILLING'] = pd.to_datetime(cs_data['MTH/YR OF BILLING'], format='%Y%m')\n",
    "   transformed_data['TimeframeStart'] = cs_data['MTH/YR OF BILLING'].dt.to_period('M').dt.to_timestamp()\n",
    "   transformed_data['TimeframeEnd'] = cs_data['MTH/YR OF BILLING'] + pd.offsets.MonthEnd(0)\n",
    "   transformed_data['Month'] = transformed_data['TimeframeStart'].dt.to_period('M')\n",
    "\n",
    "   #Aggregate usage per month, village, and beneficial use category\n",
    "   aggregated_data = transformed_data.groupby(['SiteNativeID', 'Month', 'BeneficialUseCategory'])['Amount'].sum().reset_index()\n",
    "\n",
    "   #Convert 'Month' back to datetime and calculate TimeframeStart and TimeframeEnd for the final format\n",
    "   aggregated_data['TimeframeStart'] = aggregated_data['Month'].dt.to_timestamp()\n",
    "   aggregated_data['TimeframeEnd'] = aggregated_data['TimeframeStart'] + pd.offsets.MonthEnd(0)\n",
    "\n",
    "   #Adjust the column names to match the example output\n",
    "   aggregated_data = aggregated_data[['SiteNativeID', 'BeneficialUseCategory', 'TimeframeStart', 'TimeframeEnd', 'Amount']]\n",
    "   aggregated_data['VariableCV'] = aggregated_data['BeneficialUseCategory'].apply(\n",
    "    lambda x: 'Withdrawal' if x == 'Production Well' else 'Consumptive Use'\n",
    "   )\n",
    "   aggregated_data['ReportYear'] = aggregated_data['TimeframeStart'].dt.year\n",
    "\n",
    "   #Sort the data for better readability\n",
    "   aggregated_data = aggregated_data.sort_values(by=['SiteNativeID', 'TimeframeStart', 'BeneficialUseCategory'])\n",
    "   \n",
    "   return aggregated_data\n",
    "aggregated_data = transform_to_site_specific_format(cs_data)\n",
    "print(aggregated_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55a16a7",
   "metadata": {},
   "source": [
    "### Data Cleaning: Formatting Well Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27357a7",
   "metadata": {},
   "source": [
    "This function performs all the data cleaning, qa/qc filtering, and final aggregation of all well data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0542210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def well_data(well_data_url, cs_data, village_key):\n",
    "    #well data is in the same repo \n",
    "    access_token = os.getenv('GITHUB_TOKEN')\n",
    "    headers = {'Authorization': f'token {access_token}'}\n",
    "\n",
    "    #Fetch the well data from the GitHub URL\n",
    "    response_well = requests.get(well_data_url, headers=headers)\n",
    "    response_well.raise_for_status()  # Ensure we notice bad responses\n",
    "    well_data = pd.read_csv(StringIO(response_well.text))\n",
    "    \n",
    "    #Define the pattern to match 'ASPA:WATER' followed by digits\n",
    "    pattern = re.compile(r'ASPA:WATER\\s*(\\d+)')\n",
    "    \n",
    "#MATCH WELLS FROM CS_DATA TO WELLS IN THE DATAFRAME. \n",
    "\n",
    "    #Extract well numbers from 'NAME' in cs_data\n",
    "    cs_data['Well_Number'] = cs_data['NAME'].apply(lambda x: pattern.findall(x)[0] if pattern.findall(x) else None)\n",
    "    #Ensure Well_Number is of the same type for matching\n",
    "    cs_data['Well_Number'] = cs_data['Well_Number'].astype(str)\n",
    "    well_data['Well_Number'] = well_data['Well #'].astype(str)\n",
    "    \n",
    "    #Create well_data_frame containing the desired columns\n",
    "    well_data_frame = well_data[['Village', 'Well_Number', 'Lat', 'Long']].dropna(subset=['Well_Number'])\n",
    "    well_data_frame['SiteNativeID'] = well_data_frame.apply(lambda row: f\"{row['Village']}_Well_{row['Well_Number']}\", axis=1)\n",
    "    well_data_frame['SiteTypeCV'] = 'Withdrawal'\n",
    "    well_data_frame = well_data_frame.drop_duplicates()\n",
    "    well_data_frame = well_data_frame.drop(columns=['Well_Number', 'Village'])\n",
    "\n",
    "    cs_data['MTH/YR OF BILLING'] = pd.to_datetime(cs_data['MTH/YR OF BILLING'], format='%Y%m')\n",
    "    #Calculate TimeframeStart as the first day of the month\n",
    "    cs_data['TimeframeStart'] = cs_data['MTH/YR OF BILLING'].dt.to_period('M').dt.to_timestamp()\n",
    "    #Calculate TimeframeEnd as the last day of the month\n",
    "    cs_data['TimeframeEnd'] = cs_data['MTH/YR OF BILLING'] + pd.offsets.MonthEnd(0)\n",
    "\n",
    "    #Filter cs_data to include only matched wells\n",
    "    matched_well_data = cs_data[cs_data['Well_Number'].isin(well_data['Well_Number'])]\n",
    "\n",
    "    #Select the relevant columns for matched_well_data DataFrame\n",
    "    matched_well_data = matched_well_data[['Well_Number', 'TimeframeStart', 'TimeframeEnd', 'Usage', 'NAME', 'BeneficialUseCategory', 'LOSADD']]\n",
    "\n",
    "    #Map the villages using LOSADD\n",
    "    matched_well_data['Village'] = matched_well_data['LOSADD'].map(village_key)\n",
    "    \n",
    "    #Assign SiteNativeID to be the well name\n",
    "    matched_well_data['SiteNativeID'] = matched_well_data.apply(lambda row: f\"{row['Village']}_Well_{row['Well_Number']}\", axis=1)\n",
    "   \n",
    "    \n",
    "    # Create transformed_well_data similar to your workflow\n",
    "    transformed_well_data = pd.DataFrame(columns=['SiteNativeID', 'VariableSpecificUUID', 'Amount', 'BeneficialUseCategory', 'TimeframeStart', 'TimeframeEnd'])\n",
    "    transformed_well_data['SiteNativeID'] = matched_well_data['SiteNativeID']\n",
    "    transformed_well_data['VariableSpecificUUID'] = 'UTssps_V3'\n",
    "    transformed_well_data['Amount'] = matched_well_data['Usage']\n",
    "    transformed_well_data['BeneficialUseCategory'] = matched_well_data['BeneficialUseCategory']\n",
    "    transformed_well_data['TimeframeStart'] = matched_well_data['TimeframeStart']\n",
    "    transformed_well_data['TimeframeEnd'] = matched_well_data['TimeframeEnd']\n",
    "\n",
    "    #Aggregate usage per month and beneficial use category\n",
    "    transformed_well_data['Month'] = transformed_well_data['TimeframeStart'].dt.to_period('M')\n",
    "    #Filter out data points exceeding 17,520,000 gallons per month (max well is 400 gpm)\n",
    "    max_threshold = 17520000\n",
    "    total_count = transformed_well_data.shape[0]\n",
    "    filtered_out_count = transformed_well_data[transformed_well_data['Amount'] > max_threshold].shape[0]\n",
    "    transformed_well_data = transformed_well_data[transformed_well_data['Amount'] <= max_threshold]\n",
    "    \n",
    "    #Print the number of filtered data points\n",
    "    print(f\"Filtered out {filtered_out_count} data points out of {total_count} total points exceeding {max_threshold} gallons per month.\")\n",
    "    \n",
    "    \n",
    "    aggregated_well_data = transformed_well_data.groupby(['SiteNativeID', 'Month', 'BeneficialUseCategory'])['Amount'].sum().reset_index()\n",
    "\n",
    "    #Convert 'Month' back to datetime and calculate TimeframeStart and TimeframeEnd for the final format\n",
    "    aggregated_well_data['TimeframeStart'] = aggregated_well_data['Month'].dt.to_timestamp()\n",
    "    aggregated_well_data['TimeframeEnd'] = aggregated_well_data['TimeframeStart'] + pd.offsets.MonthEnd(0)\n",
    "\n",
    "    #Adjust the column names to match the example output\n",
    "    aggregated_well_data = aggregated_well_data[['SiteNativeID', 'BeneficialUseCategory', 'TimeframeStart', 'TimeframeEnd', 'Amount']]\n",
    "    aggregated_well_data['VariableCV'] = aggregated_well_data['BeneficialUseCategory'].apply(\n",
    "        lambda x: 'Withdrawal' if x == 'Production Well' else 'Consumptive Use'\n",
    "    )\n",
    "    aggregated_well_data['ReportYear'] = aggregated_well_data['TimeframeStart'].dt.year\n",
    "\n",
    "    #Sort the data for better readability\n",
    "    aggregated_well_data = aggregated_well_data.sort_values(by=['SiteNativeID', 'TimeframeStart', 'BeneficialUseCategory'])\n",
    "\n",
    "    return well_data_frame, aggregated_well_data,transformed_well_data\n",
    "\n",
    "#Call function\n",
    "\n",
    " # Remove 'Well' entries from the first aggregated data\n",
    "aggregated_data = aggregated_data[aggregated_data['BeneficialUseCategory'] != 'Production Well']\n",
    "    \n",
    "well_data_url = \"https://raw.githubusercontent.com/cshuler/ASPA_WUDR_Input_Files/main/Well%20Info%20-%20Sheet1.csv\"\n",
    "village_url = \"https://raw.githubusercontent.com/cshuler/ASPA_WUDR_Input_Files/main/Village_Centroid_points%20-%20Sheet1.csv\"\n",
    "    \n",
    "well_data_frame, aggregated_well_data,transformed_well_data = well_data(well_data_url, cs_data, village_key) \n",
    "print(aggregated_well_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c435a946",
   "metadata": {},
   "source": [
    "Plot well data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b5fbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "production_well_data = aggregated_well_data.groupby('TimeframeEnd')['Amount'].sum().reset_index()\n",
    "production_well_data['Amount_MGD'] = production_well_data['Amount'] / 30.437\n",
    "\n",
    "#Plot Line data\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x='TimeframeEnd', y='Amount_MGD', data=production_well_data, marker='o', color='red', linewidth=3.5)\n",
    "\n",
    "plt.title('Summed Well Amounts per Month')\n",
    "plt.xlabel('Month',fontsize=16)\n",
    "plt.ylabel('Amount (MGD)',fontsize=16)\n",
    "plt.yticks(fontsize=16)  # Increase y-axis labels font size\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5521c38",
   "metadata": {},
   "source": [
    "More ways to visualize well data distribution:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268c393a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_violin_box(transformed_well_data):\n",
    "    transformed_well_data['Month'] = transformed_well_data['Month'].astype(str)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    sns.boxplot(\n",
    "        x='Month', \n",
    "        y='Amount', \n",
    "        data=transformed_well_data, \n",
    "        whis=1.5, \n",
    "        width=0.1, \n",
    "        showcaps=True, \n",
    "        boxprops={'facecolor':'None'}, \n",
    "        showfliers=True,\n",
    "        medianprops={'color': 'red', 'linewidth': 2}  # Set median line color to bright red\n",
    "    )\n",
    "   \n",
    "    plt.title('Boxplot Distribution of Monthly Well Usage')\n",
    "    plt.xlabel('Month (YYYY-MM)')\n",
    "    plt.ylabel('Water Usage (Gallons per Minute)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_violin_box(transformed_well_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde0558e",
   "metadata": {},
   "source": [
    "## Final Site Specific Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9d5de2",
   "metadata": {},
   "source": [
    "Call final data: combines well data and usage data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e9353f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_aggregated_data = pd.concat([aggregated_data, aggregated_well_data], ignore_index=True)\n",
    "print(final_aggregated_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112fc90d",
   "metadata": {},
   "source": [
    "Plot final aggregated data of all Beneficial Use Categories (not wells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658b8c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grouped_data = final_aggregated_data.groupby(['TimeframeEnd', 'BeneficialUseCategory'])['Amount'].sum().reset_index()\n",
    "other_categories_data = grouped_data[grouped_data['BeneficialUseCategory'] != 'Production Well']\n",
    "other_categories_data['Amount_MGD'] = other_categories_data['Amount'] * 0.00144\n",
    "#Set up the figure and axes for the subplots\n",
    "plt.figure(figsize=(14, 10))\n",
    "#Plot for other categories\n",
    "sns.lineplot(x='TimeframeEnd', y='Amount_MGD', hue='BeneficialUseCategory', data=other_categories_data, marker='o')\n",
    "plt.title('Water Usage Over Time by Beneficial Use Category')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Total Amount (MGD)')\n",
    "plt.xticks(rotation=45) \n",
    "\n",
    "#Adjust layout to ensure plots are not overlapping\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e4158e",
   "metadata": {},
   "source": [
    "## Metadata Table Creations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155aa0d8",
   "metadata": {},
   "source": [
    "Metadata tables support the final_aggregated_data dataset that serves as supporting more detailed information to the main dataset. The required metadata tables are defined by the Wade 2.0 Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9436ffd2",
   "metadata": {},
   "source": [
    "### Metadata Table: Organization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b039c2",
   "metadata": {},
   "source": [
    "Purpose: Provide organization information that is associated with this water use data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0af3978",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is all stagnant information that is entered manually\n",
    "def organization_metadata():\n",
    "    organizations_df = pd.DataFrame(columns=[\n",
    "        'OrganizationName', 'OrganizationContactEmail', 'OrganizationContactName', \n",
    "        'OrganizationPhoneNumber', 'OrganizationWebsite', 'StateCV', 'OrganizationPurview'\n",
    "    ])\n",
    "    new_row = pd.DataFrame([{\n",
    "        'OrganizationName': 'American Samoa Power Authority',\n",
    "        'OrganizationContactEmail': 'wei@aspower.com',\n",
    "        'OrganizationContactName': 'Wei Hua-Hsien',\n",
    "        'OrganizationPhoneNumber': '1 (684) 699-1234',\n",
    "        'OrganizationWebsite': 'https://www.aspower.com/',\n",
    "        'StateCV': 'AS',\n",
    "       ' OrganizationPurview' : 'water utility, production, delivery, consumptive use '\n",
    "\n",
    "\n",
    "    }])\n",
    "    organizations_df = pd.concat([organizations_df, new_row], ignore_index=True)\n",
    "    return organizations_df\n",
    "organizations_df = organization_metadata()\n",
    "print(organizations_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637cd12d",
   "metadata": {},
   "source": [
    "### Metadate Table: Sites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b69f5dc",
   "metadata": {},
   "source": [
    "Purpose: provide high-level site description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e9a5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: the sites data is stored in the same private github repo\n",
    "def sites_metadata(cs_data, village_url, well_data_frame):\n",
    "    # Pull from private GitHub repo\n",
    "    access_token = os.getenv('GITHUB_TOKEN')\n",
    "    if not access_token:\n",
    "        raise ValueError(\"GitHub token not found in environment variables\")\n",
    "    \n",
    "    headers = {'Authorization': f'token {access_token}'}\n",
    "    \n",
    "    # Load Village Data\n",
    "    response_vill = requests.get(village_url, headers=headers)\n",
    "    response_vill.raise_for_status()\n",
    "    village_coordinates = pd.read_csv(StringIO(response_vill.text))\n",
    "    \n",
    "    # Transform Village Data\n",
    "    village_data = pd.DataFrame()\n",
    "    village_data['Lat'] = village_coordinates['Y']\n",
    "    village_data['Long'] = village_coordinates['X']\n",
    "    village_data['SiteNativeID'] = village_coordinates['VILLAGE']\n",
    "    village_data['SiteTypeCV'] = ' Village (aggregation of individual water meter use within each village boundary) '\n",
    "\n",
    "    \n",
    "    sites_df = pd.concat([village_data, well_data_frame], ignore_index=True)\n",
    "    \n",
    "    return sites_df\n",
    "\n",
    "sites_df = sites_metadata(cs_data, village_url, well_data_frame)\n",
    "print(sites_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be194b6f",
   "metadata": {},
   "source": [
    "### Metadata Table: Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eefdc3",
   "metadata": {},
   "source": [
    "Purpose: Supply more detailed information to the variable CV column from the main dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd13411b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variables_metadata():\n",
    "    variables_df = pd.DataFrame(columns=[\n",
    "        'VariableCV', 'AmountUnitCV', 'AggregationIntervalUnitCV'\n",
    "    ])\n",
    "    new_rows = pd.DataFrame([\n",
    "        {'VariableCV': 'Consumptive Use', 'AmountUnitCV': 'Gallons', 'AggregationIntervalUnitCV': 'Month'},\n",
    "        {'VariableCV': 'Withdrawal', 'AmountUnitCV': 'Gallons', 'AggregationIntervalUnitCV': 'Month'}\n",
    "    ])\n",
    "    variables_df = pd.concat([variables_df, new_rows], ignore_index=True)\n",
    "    return variables_df\n",
    "variables_df = variables_metadata()\n",
    "print(variables_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c99532",
   "metadata": {},
   "source": [
    "### Metadata Table: Water Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8059fe0f",
   "metadata": {},
   "source": [
    "Purpose: Information on where the water usage/production is coming from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace55246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def watersources_metadata():\n",
    "    watersources_df = pd.DataFrame(columns=['WaterSourceTypeCV'])\n",
    "    new_row = pd.DataFrame([{'WaterSourceTypeCV': 'Groundwater'}])\n",
    "    watersources_df = pd.concat([watersources_df, new_row], ignore_index=True)\n",
    "    return watersources_df\n",
    "watersources_df = watersources_metadata()\n",
    "print(watersources_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507091e2",
   "metadata": {},
   "source": [
    "## Uploading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509aadc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_digitalocean_spaces(file_path):\n",
    "    spaces_key = os.getenv('SPACES_KEY')\n",
    "    spaces_secret = os.getenv('SPACES_SECRET')\n",
    "    space_name = os.getenv('SPACE_NAME')\n",
    "    space_region = os.getenv('SPACE_REGION')\n",
    "\n",
    "    if not all([spaces_key, spaces_secret, space_name, space_region]):\n",
    "        raise ValueError(\"Missing DigitalOcean Spaces credentials or bucket information\")\n",
    "    \n",
    "    # Configure the boto3 client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client('s3',\n",
    "                            region_name=space_region,\n",
    "                            endpoint_url=f'https://{space_region}.digitaloceanspaces.com',\n",
    "                            aws_access_key_id=spaces_key,\n",
    "                            aws_secret_access_key=spaces_secret)\n",
    "\n",
    "    # Upload the file\n",
    "    with open(file_path, 'rb') as file:\n",
    "        client.upload_fileobj(file, space_name, os.path.basename(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4544263c",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_paths = []\n",
    "    \n",
    "final_aggregated_csv_path = '/tmp/Final_Aggregated_Data.csv'\n",
    "final_aggregated_data.to_csv(final_aggregated_csv_path, index=False)\n",
    "csv_file_paths.append(final_aggregated_csv_path)\n",
    "    \n",
    "well_data_frame_csv_path = '/tmp/Well_Data.csv'\n",
    "well_data_frame.to_csv(well_data_frame_csv_path, index=False)\n",
    "csv_file_paths.append(well_data_frame_csv_path)\n",
    "    \n",
    "sites_df = sites_metadata(cs_data, village_url, well_data_frame)\n",
    "sites_csv_path = '/tmp/Sites.csv'\n",
    "sites_df.to_csv(sites_csv_path, index=False)\n",
    "csv_file_paths.append(sites_csv_path)\n",
    "    \n",
    "organizations_df = organization_metadata()\n",
    "organizations_csv_path = '/tmp/Organization.csv'\n",
    "organizations_df.to_csv(organizations_csv_path, index=False)\n",
    "csv_file_paths.append(organizations_csv_path)\n",
    "    \n",
    "variables_df = variables_metadata()\n",
    "variables_csv_path = '/tmp/Variables.csv'\n",
    "variables_df.to_csv(variables_csv_path, index=False)\n",
    "csv_file_paths.append(variables_csv_path)\n",
    "    \n",
    "watersources_df = watersources_metadata()\n",
    "watersources_csv_path = '/tmp/WaterSources.csv'\n",
    "watersources_df.to_csv(watersources_csv_path, index=False)\n",
    "csv_file_paths.append(watersources_csv_path)\n",
    "    \n",
    "for file_path in csv_file_paths:\n",
    "        upload_to_digitalocean_spaces(file_path)\n",
    "    \n",
    "retu{\"csv_file_paths\": csv_file_paths}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42ebfd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6366ab0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a1bbd6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'_Environ' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mTypeError\u001b[0m: '_Environ' object is not callable"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.environ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662577a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
